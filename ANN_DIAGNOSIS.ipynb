{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9872b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae6973d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>911320502</td>\n",
       "      <td>B</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>898677</td>\n",
       "      <td>B</td>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.02037</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.07162</td>\n",
       "      <td>0.04074</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.08488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>873885</td>\n",
       "      <td>M</td>\n",
       "      <td>15.28</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>...</td>\n",
       "      <td>17.80</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>911201</td>\n",
       "      <td>B</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.13730</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>9012795</td>\n",
       "      <td>M</td>\n",
       "      <td>21.37</td>\n",
       "      <td>15.10</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.84</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.08666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0     87139402         B        12.32         12.39           78.85   \n",
       "1      8910251         B        10.60         18.95           69.28   \n",
       "2       905520         B        11.04         16.83           70.92   \n",
       "3       868871         B        11.28         13.39           73.00   \n",
       "4      9012568         B        15.19         13.21           97.65   \n",
       "..         ...       ...          ...           ...             ...   \n",
       "564  911320502         B        13.17         18.22           84.28   \n",
       "565     898677         B        10.26         14.71           66.20   \n",
       "566     873885         M        15.28         22.41           98.92   \n",
       "567     911201         B        14.53         13.98           93.86   \n",
       "568    9012795         M        21.37         15.10          141.30   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0        464.1          0.10280           0.06981         0.03987   \n",
       "1        346.4          0.09688           0.11470         0.06387   \n",
       "2        373.2          0.10770           0.07804         0.03046   \n",
       "3        384.8          0.11640           0.11360         0.04635   \n",
       "4        711.8          0.07963           0.06934         0.03393   \n",
       "..         ...              ...               ...             ...   \n",
       "564      537.3          0.07466           0.05994         0.04859   \n",
       "565      321.6          0.09882           0.09159         0.03581   \n",
       "566      710.6          0.09057           0.10520         0.05375   \n",
       "567      644.2          0.10990           0.09242         0.06895   \n",
       "568     1386.0          0.10010           0.15150         0.19320   \n",
       "\n",
       "     points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0        0.03700  ...         13.50          15.64            86.97   \n",
       "1        0.02642  ...         11.88          22.94            78.28   \n",
       "2        0.02480  ...         12.41          26.44            79.93   \n",
       "3        0.04796  ...         11.92          15.77            76.53   \n",
       "4        0.02657  ...         16.20          15.73           104.50   \n",
       "..           ...  ...           ...            ...              ...   \n",
       "564      0.02870  ...         14.90          23.89            95.10   \n",
       "565      0.02037  ...         10.88          19.48            70.89   \n",
       "566      0.03263  ...         17.80          28.03           113.80   \n",
       "567      0.06495  ...         15.80          16.93           103.10   \n",
       "568      0.12550  ...         22.69          21.84           152.10   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         549.1            0.1385             0.1266          0.12420   \n",
       "1         424.8            0.1213             0.2515          0.19160   \n",
       "2         471.4            0.1369             0.1482          0.10670   \n",
       "3         434.0            0.1367             0.1822          0.08669   \n",
       "4         819.1            0.1126             0.1737          0.13620   \n",
       "..          ...               ...                ...              ...   \n",
       "564       687.6            0.1282             0.1965          0.18760   \n",
       "565       357.1            0.1360             0.1636          0.07162   \n",
       "566       973.1            0.1301             0.3299          0.36300   \n",
       "567       749.9            0.1347             0.1478          0.13730   \n",
       "568      1535.0            0.1192             0.2840          0.40240   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0         0.09391          0.2827          0.06771  \n",
       "1         0.07926          0.2940          0.07587  \n",
       "2         0.07431          0.2998          0.07881  \n",
       "3         0.08611          0.2102          0.06784  \n",
       "4         0.08178          0.2487          0.06766  \n",
       "..            ...             ...              ...  \n",
       "564       0.10450          0.2235          0.06925  \n",
       "565       0.04074          0.2434          0.08488  \n",
       "566       0.12260          0.3175          0.09772  \n",
       "567       0.10690          0.2606          0.07810  \n",
       "568       0.19660          0.2730          0.08666  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"C:/Users/PARCHU/Downloads/wbcd (1).csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05616fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>13.17</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.05549</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.02037</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.07162</td>\n",
       "      <td>0.04074</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.08488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>15.28</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>...</td>\n",
       "      <td>17.80</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.13730</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>21.37</td>\n",
       "      <td>15.10</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.84</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.08666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          12.32         12.39           78.85      464.1          0.10280   \n",
       "1          10.60         18.95           69.28      346.4          0.09688   \n",
       "2          11.04         16.83           70.92      373.2          0.10770   \n",
       "3          11.28         13.39           73.00      384.8          0.11640   \n",
       "4          15.19         13.21           97.65      711.8          0.07963   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        13.17         18.22           84.28      537.3          0.07466   \n",
       "565        10.26         14.71           66.20      321.6          0.09882   \n",
       "566        15.28         22.41           98.92      710.6          0.09057   \n",
       "567        14.53         13.98           93.86      644.2          0.10990   \n",
       "568        21.37         15.10          141.30     1386.0          0.10010   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0             0.06981         0.03987      0.03700         0.1959   \n",
       "1             0.11470         0.06387      0.02642         0.1922   \n",
       "2             0.07804         0.03046      0.02480         0.1714   \n",
       "3             0.11360         0.04635      0.04796         0.1771   \n",
       "4             0.06934         0.03393      0.02657         0.1721   \n",
       "..                ...             ...          ...            ...   \n",
       "564           0.05994         0.04859      0.02870         0.1454   \n",
       "565           0.09159         0.03581      0.02037         0.1633   \n",
       "566           0.10520         0.05375      0.03263         0.1727   \n",
       "567           0.09242         0.06895      0.06495         0.1650   \n",
       "568           0.15150         0.19320      0.12550         0.1973   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.05955  ...         13.50          15.64            86.97   \n",
       "1           0.06491  ...         11.88          22.94            78.28   \n",
       "2           0.06340  ...         12.41          26.44            79.93   \n",
       "3           0.06072  ...         11.92          15.77            76.53   \n",
       "4           0.05544  ...         16.20          15.73           104.50   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "564         0.05549  ...         14.90          23.89            95.10   \n",
       "565         0.07005  ...         10.88          19.48            70.89   \n",
       "566         0.06317  ...         17.80          28.03           113.80   \n",
       "567         0.06121  ...         15.80          16.93           103.10   \n",
       "568         0.06183  ...         22.69          21.84           152.10   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         549.1            0.1385             0.1266          0.12420   \n",
       "1         424.8            0.1213             0.2515          0.19160   \n",
       "2         471.4            0.1369             0.1482          0.10670   \n",
       "3         434.0            0.1367             0.1822          0.08669   \n",
       "4         819.1            0.1126             0.1737          0.13620   \n",
       "..          ...               ...                ...              ...   \n",
       "564       687.6            0.1282             0.1965          0.18760   \n",
       "565       357.1            0.1360             0.1636          0.07162   \n",
       "566       973.1            0.1301             0.3299          0.36300   \n",
       "567       749.9            0.1347             0.1478          0.13730   \n",
       "568      1535.0            0.1192             0.2840          0.40240   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0         0.09391          0.2827          0.06771  \n",
       "1         0.07926          0.2940          0.07587  \n",
       "2         0.07431          0.2998          0.07881  \n",
       "3         0.08611          0.2102          0.06784  \n",
       "4         0.08178          0.2487          0.06766  \n",
       "..            ...             ...              ...  \n",
       "564       0.10450          0.2235          0.06925  \n",
       "565       0.04074          0.2434          0.08488  \n",
       "566       0.12260          0.3175          0.09772  \n",
       "567       0.10690          0.2606          0.07810  \n",
       "568       0.19660          0.2730          0.08666  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data.iloc[:,2:]\n",
    "y=data.iloc[:,1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd0e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7401c183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      B\n",
       "1      B\n",
       "2      B\n",
       "3      B\n",
       "4      B\n",
       "      ..\n",
       "564    B\n",
       "565    B\n",
       "566    M\n",
       "567    B\n",
       "568    M\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39aa6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a661f05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10414738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx,testx,trainy,testy=train_test_split(x,y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620d7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "trainx=sc.fit_transform(trainx)\n",
    "testx=sc.fit_transform(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2de39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19781106, -0.62003089,  0.25891082, ...,  1.2850756 ,\n",
       "         1.0285148 ,  1.18040973],\n",
       "       [ 0.28901788, -1.42103746,  0.21802142, ..., -0.51618443,\n",
       "        -0.6801246 , -0.8879946 ],\n",
       "       [-0.35228008, -0.73578328, -0.37962464, ..., -0.48490221,\n",
       "         0.58034709, -0.31923666],\n",
       "       ...,\n",
       "       [-1.46329317, -0.1037752 , -1.33412363, ..., -0.02877765,\n",
       "         0.32825275,  1.12715524],\n",
       "       [-0.71140694, -0.73578328, -0.69724027, ..., -0.27233207,\n",
       "        -0.18682889, -0.21805314],\n",
       "       [-0.64870225, -1.08767057, -0.58902792, ..., -0.83436929,\n",
       "        -0.30665151,  1.02597171]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b900ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b15a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Dense(10,kernel_initializer='uniform',activation='relu',input_dim=30))\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab919879",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(10,kernel_initializer='uniform',activation='relu'))\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "303ff58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6c28def",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5f8ce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 24ms/step - loss: 0.6930 - accuracy: 0.5209\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6922 - accuracy: 0.6154\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.6176\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.6176\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.6264\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.6396\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.7077\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.7429\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.8308\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.8681\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.8989\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.9077\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.9143\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.9231\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.9341\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.9297\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.9363\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.9275\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.9275\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.9385\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.9385\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.9363\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2864 - accuracy: 0.9429\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9407\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2205 - accuracy: 0.9473\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9451\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1838 - accuracy: 0.9516\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9560\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1638 - accuracy: 0.9560\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1533 - accuracy: 0.9648\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9648\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9648\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9692\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9692\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9736\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9736\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9692\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9692\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9758\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9780\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9802\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9758\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9802\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9802\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9824\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9824\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9846\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9824\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9846\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9846\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9846\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9868\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9802\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9890\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9912\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9868\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9868\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9868\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9890\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9912\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9890\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9890\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9868\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9868\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9890\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9890\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9890\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9912\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9846\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9912\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9912\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9912\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9912\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9890\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9868\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9912\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9912\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9912\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9912\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9912\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9912\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9912\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9890\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9912\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9912\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9912\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9912\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9912\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9890\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9912\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9890\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.8574591e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9989712e-01],\n",
       "       [9.9999338e-01],\n",
       "       [1.1008382e-03],\n",
       "       [2.3432046e-02],\n",
       "       [9.4425678e-04],\n",
       "       [7.5921357e-02],\n",
       "       [3.8192931e-05],\n",
       "       [3.5765767e-04],\n",
       "       [4.7197938e-04],\n",
       "       [4.3696165e-04],\n",
       "       [5.4091215e-03],\n",
       "       [6.4488053e-03],\n",
       "       [6.3224456e-05],\n",
       "       [9.9998093e-01],\n",
       "       [3.6868969e-05],\n",
       "       [2.4325550e-03],\n",
       "       [3.6170268e-01],\n",
       "       [2.1592408e-05],\n",
       "       [1.2506843e-03],\n",
       "       [4.4538677e-03],\n",
       "       [9.9820513e-01],\n",
       "       [4.9900091e-01],\n",
       "       [3.5924911e-03],\n",
       "       [7.3901679e-06],\n",
       "       [9.6807094e-07],\n",
       "       [1.5289219e-05],\n",
       "       [4.1985780e-02],\n",
       "       [3.4545660e-03],\n",
       "       [3.3221543e-03],\n",
       "       [9.9598473e-01],\n",
       "       [8.9955330e-04],\n",
       "       [3.8850307e-04],\n",
       "       [6.6473782e-03],\n",
       "       [8.0560446e-03],\n",
       "       [9.9999344e-01],\n",
       "       [1.7401871e-05],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999607e-01],\n",
       "       [1.1735260e-03],\n",
       "       [2.4839044e-03],\n",
       "       [4.0977299e-03],\n",
       "       [2.0849705e-04],\n",
       "       [2.4029613e-04],\n",
       "       [5.7472289e-03],\n",
       "       [3.6996603e-04],\n",
       "       [1.5501678e-03],\n",
       "       [6.5299869e-04],\n",
       "       [1.1073351e-03],\n",
       "       [9.9963188e-01],\n",
       "       [5.7661533e-04],\n",
       "       [8.8801980e-04],\n",
       "       [1.6853780e-02],\n",
       "       [1.8744375e-05],\n",
       "       [1.0000000e+00],\n",
       "       [9.9997163e-01],\n",
       "       [9.9798644e-01],\n",
       "       [1.8217292e-05],\n",
       "       [2.1603107e-03],\n",
       "       [8.0193341e-02],\n",
       "       [5.9348345e-04],\n",
       "       [8.7978917e-01],\n",
       "       [1.9929972e-01],\n",
       "       [1.8447348e-05],\n",
       "       [9.9948406e-01],\n",
       "       [2.6549786e-02],\n",
       "       [9.9996316e-01],\n",
       "       [2.9572037e-05],\n",
       "       [1.0198928e-05],\n",
       "       [1.3399422e-03],\n",
       "       [2.7091503e-02],\n",
       "       [1.0000000e+00],\n",
       "       [4.6012104e-03],\n",
       "       [9.9998808e-01],\n",
       "       [3.1483173e-04],\n",
       "       [9.9835825e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9970800e-01],\n",
       "       [7.8169078e-02],\n",
       "       [2.5933683e-03],\n",
       "       [1.3082236e-02],\n",
       "       [3.6735117e-02],\n",
       "       [5.1055849e-03],\n",
       "       [9.9999982e-01],\n",
       "       [1.2578070e-03],\n",
       "       [9.6382725e-01],\n",
       "       [4.9038231e-03],\n",
       "       [9.2575932e-01],\n",
       "       [9.9967861e-01],\n",
       "       [1.0000000e+00],\n",
       "       [3.3370584e-02],\n",
       "       [1.0000000e+00],\n",
       "       [1.1910498e-02],\n",
       "       [5.2558822e-05],\n",
       "       [3.7833452e-03],\n",
       "       [9.9999964e-01],\n",
       "       [1.2476444e-03],\n",
       "       [1.3002065e-01],\n",
       "       [2.2108041e-05],\n",
       "       [1.4075637e-04],\n",
       "       [9.9999964e-01],\n",
       "       [9.9981630e-01],\n",
       "       [5.4907799e-04],\n",
       "       [1.0372098e-04],\n",
       "       [1.0000000e+00],\n",
       "       [2.4345219e-03],\n",
       "       [1.0000000e+00],\n",
       "       [5.1114589e-02],\n",
       "       [9.9820906e-01],\n",
       "       [1.1100841e-04],\n",
       "       [1.1341244e-02],\n",
       "       [1.5910417e-02],\n",
       "       [9.9988073e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(trainx,trainy,batch_size=100,epochs=100)\n",
    "pred_y=classifier.predict(testx)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de710608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y=(pred_y>0.5)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee8b179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76,  1],\n",
       "       [ 3, 34]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(testy,pred_y)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05d4399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=(76+34)/(76+34+1+3)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91e57bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of given dataset:0.96\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy of given dataset:{:.2f}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "804b4b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed027a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b98f472bb8ba48098397e3b897b5be76f7bf0e62d98845cdb0e8066dc5677259"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
